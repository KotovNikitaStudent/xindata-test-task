# Xindata — Тестовое задание

CLI-инструмент для анализа статистических данных о доходах фрилансеров.  

## Системные требования

### Для запуска программы:
- **Python 3.10**
- **SQLite**
- **Pandas** (для работы с данными)
- **Argparse** (для CLI)
- **Ollama** (локальный сервер LLM)
- **OpenAI** (для обращения к LLM)

### Для работы с моделью `llama3:8b-instruct-q3_K_M`:
- Операционная система: **Linux**
- Рекомендуется наличие NVIDIA GPU (опционально, ускоряет работу)
- Минимум **8 ГБ оперативной памяти**
- Место на диске: **минимум 5 ГБ** свободного места

## Установка Ollama (локально, Linux)

Загрузите и установите Ollama:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Проверьте установленную версию:

```bash
ollama --version
```

## Скачивание модели llama3

Скачайте нужную модель:

```bash
ollama pull llama3:8b-instruct-q3_K_M
```

Проверьте список загруженных моделей:

```bash
ollama list
```

Пример вывода:

```
NAME                         ID              SIZE      MODIFIED       
llama3:8b-instruct-q3_K_M    726a1960bfed    4.0 GB    52 minutes ago 
```

## Запуск локального сервера Ollama

Для общения с моделью через API запустите сервер:

```bash
ollama serve
```

Сервер будет доступен по адресу: `http://localhost:11434`

Вы можете проверить его работу следующим запросом:

```bash
curl -X POST http://localhost:11434/api/generate -d '{
  "model": "llama3:8b-instruct-q3_K_M",
  "prompt": "Why is the sky blue?"
}'
```

## Подготовка данных

Данные загружаются из CSV-файла (`data/freelancer_earnings_bd.csv`) в SQLite базу (`freelancers.db`) с таблицей `freelancers`.

Для загрузки используйте флаг:

```bash
poetry run python src/main.py --load-table
```

## Пример использования CLI

### Обычный режим (только ответ):

```bash
poetry run python src/main.py --ask "Какие есть категории фрилансеров и сколько их в каждой категории?"
```

### Расширенный режим (SQL + результат + объяснение):

```bash
poetry run python src/main.py --ask "Какие есть категории фрилансеров и сколько их в каждой категории?" --verbose
```

## Архитектура решения

1. **Загрузка данных** в SQLite из CSV.
2. **Анализ структуры таблицы**: определяются:
   - Все колонки.
   - Категориальные поля и их уникальные значения.
   - Числовые поля.
  Происходит автоматическое кэширование структуры таблицы
  в папке .cache как json файл, и обновляется если изменяется структура таблицы
3. **Формирование промпта для LLM**, включающего:
   - Имя таблицы.
   - Названия столбцов.
   - Информация о категориальных и числовых полях.
   - Пользовательский вопрос.
4. **Генерация SQL-запроса** моделью.
5. **Выполнение SQL-запроса** к БД.
6. **Формирование второго промпта**, содержащего:
   - Результат выполнения SQL запроса.
   - Пользовательский вопрос.
7. **Интерпретация результата** моделью и вывод человекочитаемого ответа.

## Установка зависимостей

### Установка зависимостей через Poetry

Убедитесь, что Poetry установлен:

```bash
poetry --version
```

Если Poetry не установлен:

```bash
curl -sSL https://install.python-poetry.org | python3 -
```

### Установка проекта и зависимостей

Создайте виртуальное окружение и установите зависимости:

```bash
poetry install
```

Если у вас нет файла `pyproject.toml`, создайте его:

```bash
poetry init
```

И добавьте нужные зависимости, например:

```bash
poetry add pandas openai argparse
```

## Возможности CLI

| Флаг | Описание |
|------|----------|
| `--load-table` | Загружает CSV-файл в SQLite-базу |
| `--ask "вопрос"` | Задаёт вопрос системе, получает ответ от LLM |
| `--verbose` | Выводит SQL-запрос и результат выполнения |


## Оценка эффективности и точности работы системы

Система была протестирована на ряде пользовательских запросов к таблице freelancers. Были отобраны как вопросы из
 тестового задания, так и дополнительные.

Для оценки точности использовались следующие метрики:

- Корректность SQL-запроса — проверяется выполнение запроса без ошибок и соответствие структуре таблицы.
- Семантическая точность — отражает, отвечает ли результат запроса из БД на исходный вопрос.
- Интерпретация LLM — оценивается, соответствует ли интерпретация чисел, агрегатов и процентов логике запроса.

Из 3 тестовых вопросов:

- SQL-запрос сгенерирован правильно — в 3/3 случаев.
- Семантическая точность - в 3/3 случаев.
- Ответ верно интерпретирован LLM — в 3/3 случаев.

Из 10 дополнительных вопросов:

- SQL-запрос сгенерирован правильно — в 8/10 случаев.
- Семантическая точность - в 8/10 случаев.
- Ответ верно интерпретирован LLM (у учетом ошибок выполенения запроса или отсутствия релевантных данных для данного пользовательского вопроса) — в 10/10 случаев.

## Тестовые вопросы

1. Насколько выше доход у фрилансеров, принимающих оплату в криптовалюте, по сравнению с другими способами оплаты?
2. Как распределяется доход фрилансеров в зависимости от региона проживания?
3. Какой процент фрилансеров, считающих себя экспертами, выполнил менее 100 проектов?

## Дополнительные вопросы

1. Какая средняя ставка у фрилансеров с разным уровнем опыта?
2. Какие платформы приносят фрилансерам наибольший средний доход?
3. В каких регионах фрилансеры получают выше средней клиентской оценки?
4. Какой процент всех проектов был выполнен на условиях фиксированной оплаты?
5. Сколько фрилансеров работают в каждой категории?
6. Какая категория фрилансеров имеет наибольшее среднее количество завершённых проектов?
7. Какая доля фрилансеров получает оплату через PayPal?
8. Какая средняя продолжительность проекта у начинающих фрилансеров?
9. Как соотносится реферальная ставка с маркетинговыми затратами?
10. Какие методы оплаты предпочитают фрилансеры с наибольшим доходом (топ-3)?

## Критерии оценки качества решения

1. Точность SQL-запроса
  - Проверяется выполнение запроса в SQLite без ошибок.
  - Сопоставляется структура запроса с вопросом пользователя.
  - Оценивается наличие логических или синтаксических ошибок.

2. Точность интерпретации результата
  - Ответ LLM должен содержать численно правильные значения и корректные формулировки.
  - Проверяется, использует ли LLM контекст вопроса при интерпретации (например, "выше", "ниже", "процент").

3. Обработка пользовательских ошибок
  - Система должна быть устойчивой к неформулированным вопросам и возвращать осмысленные SQL-запросы или указывать, что не может интерпретировать.

4. Время ответа
  - В среднем 3 секунды на полный цикл (формирование запроса, выполнение, интерпретация).

5. Гибкость и расширяемость
  - Легко подменить LLM (через ollama).
  - Можно заменить датасет, просто загрузив его через --load-table.

## Обоснование выбранного подхода

Основная идея — разделить процесс на этапы и явно управлять контекстом, передаваемым языковой модели:

- Получение метаинформации о таблице.
- Подготовка промпта с описанием структуры, категорий, чисел.
- Генерация чистого SQL-запроса без комментариев.
- Отдельное интерпретирование результата.

Такой подход позволяет:

- Избежать необходимости загружать весь датасет в LLM, что запрещено в условиях тестового задания.
- Обеспечить гибкость — можно работать с любым датасетом схожей структуры.
- Повысить надежность: метаинформация кэшируется и формируется заранее.

## Что сработало / Что не сработало

### Что сработало:

- Выделение категориальных и числовых колонок перед генерацией SQL.
- Деление промптов на два этапа (SQL → интерпретация).
- Использование llama3 через ollama — быстрое локальное выполнение без доступа к API.

### Что не сработало:

- В некоторых случаях LLM генерировал деление a / b * 100, что приводило к 0.0 из-за округления. Решено путём уточнения в промпте порядка операций.
- Иногда генерация подзапросов была избыточной. Добавлено ограничение в промпт: «не оборачивай без необходимости».
- Некорректные вопросы или запросы, возвращающие пустой результат, обрабатываются на ранних этапах — при проверке пустого DataFrame либо до выполнения SQL.
- Изначально рассматривался запуск агрегаций через pandas, но идея оставлена из-за зависимости от среды выполнения, сложности изоляции кода, необходимости импорта библиотек и их установки.

## Критерии самооценки

| **Критерий**                          | **Оценка** | **Комментарий**                                                                           |
| ------------------------------------- | ---------- | ----------------------------------------------------------------------------------------- |
| **Точность SQL-запросов**             | 11/13      | Почти все запросы корректны; редкие ошибки с процентами или лишними подзапросами          |
| **Интерпретация результата LLM**      | 13/13      | Интерпретация в целом точная (с учетом некорректных вопросов или пустых для вопроса)           |
| **Стабильность / отказоустойчивость** | 13/13      | Система обрабатывает большинство ошибок, включая невалидные вопросы или пустые результаты |
| **Производительность**                | 9/10       | Среднее время ответа <3 сек, локальное выполнение быстрой модели через Ollama             |
| **Соответствие требованиям задания**  | 10/10      | Полное покрытие всех требований, в том числе обработки промптов и анализа схемы           |
